# ğŸ“š Scraping â€” Google Books â†’ CSV & SQLite

Ce projet illustre un petit pipeline Ã©ducatif pour **collecter â†’ nettoyer â†’ stocker** des donnÃ©es de livres Ã  partir de lâ€™**API Google Books**, avec export en **CSV** et insertion dans une base **SQLite**.

---

## ğŸš€ FonctionnalitÃ©s

- RÃ©cupÃ©ration de livres via **Google Books API** avec les paramÃ¨tres : `q=food`, `filter=paid-ebooks`, `orderBy=relevance`, `maxResults=40`  
- Transformation de la rÃ©ponse API â†’ **liste de dictionnaires** â†’ **DataFrame pandas**
- Nettoyage des donnÃ©es : suppression des valeurs manquantes (`price`, `rating`), ajout dâ€™une colonne `availability`, rÃ©initialisation des index
- Sauvegarde en **CSV brut** (`data/data_api.csv`)
- Insertion dans une **base SQLite** (`book_store.db`, table `book_store`)
- Fonction principale `run_api_pipeline()` qui exÃ©cute toutes les Ã©tapes automatiquement

---

## ğŸ—‚ï¸ Structure du projet

```
scraping/
â”œâ”€ data/                  # Exports CSV
â”œâ”€ get_data/              # RÃ©cupÃ©ration de donnÃ©es (API / scraping)
â”œâ”€ process_data/          # Nettoyage et typage
â”œâ”€ pipelines/             # Fonctions de chargement et pipeline complet
â”œâ”€ notebooks/             # (Optionnel) Exploration
â”œâ”€ main.py                # Point dâ€™entrÃ©e principal
â””â”€ requirements.txt       # DÃ©pendances Python
```

---

## âš™ï¸ Installation

**PrÃ©requis :** Python 3.10 ou plus

```bash
git clone https://github.com/emese007/scraping.git
cd scraping

# (Optionnel) environnement virtuel
python -m venv .venv
source .venv/bin/activate  # sous Windows : .venv\Scripts\activate

# Installation des dÃ©pendances
pip install -r requirements.txt
```

Si le fichier `requirements.txt` est incomplet, ajoutez :  
```
pandas
requests
```

---

## â–¶ï¸ ExÃ©cution du pipeline

Lancer simplement :

```bash
python main.py
```

Le script :
1. interroge lâ€™API Google Books,  
2. crÃ©e une liste de dictionnaires,  
3. convertit la liste en DataFrame,  
4. enregistre les donnÃ©es brutes en CSV,  
5. nettoie les donnÃ©es,  
6. insÃ¨re les rÃ©sultats dans la base SQLite.

---

## ğŸ§¾ DonnÃ©es gÃ©nÃ©rÃ©es

- **CSV brut :** `data/data_api.csv`  
- **Base SQLite :** `data/book_store.db` (table `book_store`)

Colonnes principales :  
- `title` â†’ titre du livre  
- `price` â†’ prix (float)  
- `rating` â†’ note moyenne (float ou entier)  
- `availability` â†’ boolÃ©en (par dÃ©faut `False`)

---

## ğŸ‘¤ Auteurs

Projet rÃ©alisÃ© par [@emese007]
Formation IA - Simplon Montpellier (2025â€“2026)
